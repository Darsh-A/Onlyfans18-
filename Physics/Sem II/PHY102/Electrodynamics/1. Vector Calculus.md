## Differential Calculus
Suppose we have a function of one variable: $f(x)$. It is important to always remember what $df/dx$ represents.
It tells us how much the value of $f(x)$ will vary when we change the argument $x$ by a very small amount.

### Single Variate Functions
Let $f(x)$ be a differentiable function at $x$.
Then, $$
\require{physics}
\Delta f = \frac{df}{dx} \Delta x
$$
The derivative of $f(x)$ is therefore defined as:
$$
\require{physics}
f'(x)= \frac{df}{dx}=\lim_{ h \to 0 } \frac{f(x+h)-f(x)}{h}
$$

### Multi Variate Functions
#### Partial Differentiation 
Let $f(x,y,z)$ be differentiable function at $x,y,z$. Then partial derivative of $x,y,z$ is defined as:
$$
\frac{ \partial f(x,y,z) }{ \partial x } = \lim_{ h \to 0 } \frac{f(x+h, y, z)-f(x, y, z)}{h}
$$
$$
\require{physics}
\frac{ \partial f(x,y,z) }{ \partial y } = \lim_{ h \to 0 } \frac{f(x, y+h, z)-f(x, y, z)}{h}
$$
$$
\require{physics}
\frac{ \partial f(x,y,z) }{ \partial z } = \lim_{ h \to 0 } \frac{f(x, y, z+h)-f(x, y, z)}{h}
$$

Also,
$$
f(x_{0},\dots,x_{i}+h,\dots,x_{n}) \approx f(x_{0},\dots,x_{i},\dots,x_{n}) + \frac{ \partial f }{ \partial x_{i} }h 
$$
##### Multiple Partial Differentiations
Let $f(x,y,z)$ be differentiable function at $x,y,z$. Then there are multiple partial derivatives which can be applied on the same function.

$$
\frac{ \partial }{ \partial x }\left( \frac{ \partial f(x,y) }{ \partial y }  \right) = \frac{ \partial^{2} f }{ \partial x \: \partial y }  
$$

The operation performed later is written to left in denominator.

###### Order of Operations
If a given function $f(x_{0},x_{1},x_{2},\dots)$ is differentiable at points ${x_{0},x_{1},x_{2},\dots}$
Then, the order of partial differentiation on the function does not matter.
$$
\frac{ \partial f(x_{0},x_{1},x_{2},\dots) }{ \partial x_{0} \: \partial x_{1} \: \partial x_{2}\dots } = \frac{ \partial f(x_{0},x_{1},x_{2},\dots) }{ \partial x_{n} \: \partial x_{n-1} \: \partial x_{n-2}\dots }  
$$

```ad-note
title: Proof
color: 0,255,255

$$
\require{physics}
\begin{align}
\frac{ \partial }{ \partial x }\left( \frac{ \partial f }{ \partial y }  \right) &= \frac{ \partial }{ \partial x } \left( \lim_{ h \to 0 } \frac{f(x,y+h)-f(x,y)}{h} \right) \\
&= \frac{ \partial }{ \partial x } \left( \lim_{ h \to 0 } \frac{f(x,y+h)}{h} -\lim_{ h \to 0 } \frac{f(x,y)}{h} \right) \\
&= \lim_{ h,k \to 0 } \frac{f(x+k,y+h)}{kh}-\lim_{ h,k \to 0 } \frac{f(x,y)}{kh} \\
&= \lim_{h,k \to 0} \frac{f(x+k,y+h) - f(x,y)}{kh}
\end{align}
$$

which can be verified to be an order agnostic process.
```




### Finding $d f$

We start by trying to figure out how $f(x,y,z)$ will behave with very small changes to all three parameters. We find:
$$
f(x+a,y+b,z+c) \approx f(x,y,z) + \frac{ \partial f }{ \partial x } a + \frac{ \partial f }{ \partial y } b + \frac{ \partial f }{ \partial z } c 
$$
```ad-note
title:  Proof
color: 0, 255, 255

Proof to be written later...

```

Therefore:
$$
df= \sum_{i=0}^{n} \frac{ \partial f }{ \partial x_{i} } dx_{i}
$$

##### Example:

```ad-note
title: Question
color: 255, 0, 0

Let $u$ be a function satisfying:

$\:$

$$
du=xdy+ydx
$$
Find $u$.

```

$$
du = \frac{ \partial u }{ \partial x } dx + \frac{ \partial u }{ \partial y } dy
$$
Therefore:
$$
\begin{align}
 \frac{ \partial u }{ \partial x } &=y \\
 \partial u &= y\p 
\end{align}
$$
## Gradient
- Gradient is a vector operator. It should be treated very similar to a function but instead of acting on numbers, it acts on vectors.
- The gradient operator is represented by $\nabla$.
- Applying the gradient operator looks very similar to multiplication but it is *not multiplication*.
$$
\require{physics}
\nabla = \hat{x} \frac{\partial}{\partial x} + \hat{y} \frac{\partial}{\partial y} + \hat{z} \frac{\partial}{\partial z} 
$$

$\nabla$ behaves similar to vector despite being a vector operator. Therefore $\nabla$ can act in *3* ways:
1. On a scalar function $T$: $\nabla T$
2. On a vector function $v$, via dot product also called **Divergence**: $\nabla . v$
3. On a vector function $v$, via cross product also called **Curl**: $\nabla \times v$

### Scalar Operations
A scalar function $T$ is a multi-variate function: $f(x_{1},x_{2},x_{3}\dots)$
Operating $\nabla$ on $T$ results in
$$
\require{physics}
\nabla T = \frac{\partial T}{\partial x_{1}} + \frac{\partial T}{\partial x_{2}} + \frac{\partial T}{\partial x_{3}} + \dots
$$
#### Example
 ![](https://i.imgur.com/Fg99nQy.png)

### Divergence {Dot Product}
We can construct the divergence from the definition of gradient.
$$
\require{physics}
\begin{align}
\nabla \cdot v &= (\hat{x} \frac{\partial}{\partial x} + \hat{y} \frac{\partial}{\partial y} + \hat{z} \frac{\partial}{\partial z} ) . (v_{x} \hat{x} + v_{y} \hat{y} + v_{z} \hat{z}) \\
&= \frac{\partial v_{x}}{\partial x} + \frac{\partial v_{y}}{\partial y} + \frac{\partial v_{z}}{\partial z} 
\end{align}
$$
The divergence of a vector field is a mathematical operation that describes the flow of the field out of a given point.

Geometrically, the divergence of a vector field at a point is a scalar that represents the rate at which the field is spreading out or converging at that point. If the divergence at a point is positive, then the field is spreading out from that point; if it is negative, then the field is converging towards that point; and if it is zero, then the field is neither spreading out nor converging at that point.

### Curl {Cross Product}
We can construct curl as the following
$$
\require{physics}
\nabla \cross v = \det\begin{pmatrix}
\mathbf{i} & \mathbf{j} & \mathbf{k} \\
\frac{\partial}{\partial x} & \frac{\partial}{\partial y} & \frac{\partial}{\partial z} \\
v_{x} & v_{y} & v_{z} \\
\end{pmatrix}
$$

