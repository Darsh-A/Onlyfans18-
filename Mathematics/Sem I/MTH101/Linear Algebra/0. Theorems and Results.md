## [[2. Matrices]]

#### Lemma 2.1
Suppose $A$ is an $m$x$m$ matrix which has a left inverse $B_{1}$ and a right inverse $B_{2}$. Then $B_{1}=B_{2}$

#### Lemma 2.2
Let $A \in M_{m\text{x}m}(\mathbb{R})$ have a left inverse $B$. Then for any $m$x$1$ matrix $Y$,
there exists an $m$x$1$ matrix $X$ such that $AX = Y$

#### Lemma 2.3
Let $J \in M_{m\text{x}m}(\mathbb{R})$  such that $JX=X$ for all $X \in M_{m	\text{x}m}(\mathbb{R})$.
Then, $J = I_{m}$

#### Proposition 1
Let $A \in M_{m\text{x}m}(\mathbb{R})$ and let $B$ be its **Left Inverse**
Then, $B$ is also the **Right Inverse** of $A$

#### Corollary 1
Let $A \in M_{m\text{x}m}(\mathbb{R})$  and  let $B$ be a right inverse of $A$. Then, $B$ is also a left inverse of $A$

---

## [[3. Vector Spaces]]

#### Properties
1. $0 \cdot v = \bar{0} \:\:\:\forall \:\:v \in \mathbb{R}$
2. $-v = (-1) \cdot v \:\:\: \forall \:\: v \in \mathbb{R}$

#### Theorem 3.1
Let $V$ be a vector space and let $S \subset V$
Let $v \in V$ 
$Span(S \:\cup \: \{v\}) \neq Span(S) \iff v \notin Span(S)$
( $\iff$ : if and only if )

#### Proof that all three statements implies each other that is they are equivalent

 Let $V$ be a vector space
 Let $S \subset V$ . Then,
 1. $S$ is linearly Independent
 2. Any element of $Span(S)$ can be uniquely written in the form $\sum_{v \in S}a_{v} \cdot v$
 3. If $\sum_{v \in S}a_{v} \cdot v = \bar{0}$  ,  then we must have $a_{v} = 0 \:\: \forall \:\: v$  
    There is no collection of real numbers $\{a_{v}\}_{v \in S}$ such that at least one of them is non-zero and $\sum a_{v}\cdot v =0$

---

## [[4. Determinants]]

#### Theorem 4.1
A square matrix $A$ is invertible $\iff$ $\det(A) \neq 0$
If $\det(A) \neq 0$
	$\color{#d693f5}A^{-1}=\det(A)^{-1} \cdot C^{tr}$
where $C =$ cofactor matrix of A

---

## [[5. Linear Transformation]]

~~

---

## [[6. Dimensions]]

#### Proving $\phi_{B}$ is bijection and hence a linear transformation
[[6. Dimensions#$ phi_{B}$ is a 1-1 function | 1-1 function]]
[[6. Dimensions#$ phi_{B}$ is an onto function | onto function]]

#### Theorem 6.1
Let $\{v_{1},\dots v_{n}\} \subseteq \mathbb{R}^{n}$  be a spanning set. Then $m \geq n$.

#### Theorem 6.2
Let $\{v_{1}\dots v_{m}\}$ be a linearly independent set in $\mathbb{R}^{n}$.
Then, $n \geq m$ .

#### Theorem 6.3
Let $V$ be a finite dimensional vector space. Then, any basis of $V$ has the same number of elements

#### Result 1
Any basis of $\mathbb{R}^{n}$ has exactly $n$ elements

---

## [[7. Linear Independence]]

#### Theorem 7.1
Suppose some $\color{#d693f5}k\text{x}k\:\:minor$ of $A$ has non-zero determinant . Then $\color{#d693f5}column-rank$ of $A$ is $\geq k$ 

#### Theorem 7.2
$Colm.rank(A) = Row.rank(A)$
Thus we can just say $Rank(A)$

#### Result 1
title: Important Observation
Number of free variables = dimension of solution space

#### Result 2
$Rank(A)+Nullity(A) =$ no. of columns of $A$

#### $Rank-Nullity$ theorem
$$
\begin{align}
Rank(T)+dim(ker\:T) &=n \\
&= dim. of\:domain\:of\:T
\end{align}
$$

----






